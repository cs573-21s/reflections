Reflections 1
===

![screengrab from The Social Dilemma](/images/dataviz-reflection1.png)

Category: Affect detection

I finally succumbed to peer pressure and watched this documentary about the ethical and moral dilemma that we face today due to social media in our lives.

This screenshot from the documentary was particularly important in communicating the rather complicated domain of affect detection. When I started studying affect detection papers, it took me a while to grasp the idea that each affect is detected separately. As you can see in this image above, a user is scoring high numbers on multiple affects(mood): lonely(62%), nervous(80.6%). Communicating this idea through words is somewhat tricky because, intuitively, if someone is 80.6% nervous, then the remaining 19.4% would probably be some other affects that would some the users' current state to 100%. It is also rather tedious to study and realize that, as it is shown in the image, about 9 mood detection models are running parallelly and probably 13 models running to detect other attributes. The visualization effectively communicates the models running in the background and scoring highly at the moment, which would be somewhat confusing to communicate through text or tables as it the convention on most research papers.


